{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用线性回归方法，包括回归系数参数估计、回归显著性检验、回归系数检验，求出最优选模型；"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "        TV  radio  newspaper  sales\n0    230.1   37.8       69.2   22.1\n1     44.5   39.3       45.1   10.4\n2     17.2   45.9       69.3    9.3\n3    151.5   41.3       58.5   18.5\n4    180.8   10.8       58.4   12.9\n..     ...    ...        ...    ...\n195   38.2    3.7       13.8    7.6\n196   94.2    4.9        8.1    9.7\n197  177.0    9.3        6.4   12.8\n198  283.6   42.0       66.2   25.5\n199  232.1    8.6        8.7   13.4\n\n[200 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>radio</th>\n      <th>newspaper</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>230.1</td>\n      <td>37.8</td>\n      <td>69.2</td>\n      <td>22.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44.5</td>\n      <td>39.3</td>\n      <td>45.1</td>\n      <td>10.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17.2</td>\n      <td>45.9</td>\n      <td>69.3</td>\n      <td>9.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>151.5</td>\n      <td>41.3</td>\n      <td>58.5</td>\n      <td>18.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>180.8</td>\n      <td>10.8</td>\n      <td>58.4</td>\n      <td>12.9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>38.2</td>\n      <td>3.7</td>\n      <td>13.8</td>\n      <td>7.6</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>94.2</td>\n      <td>4.9</td>\n      <td>8.1</td>\n      <td>9.7</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>177.0</td>\n      <td>9.3</td>\n      <td>6.4</td>\n      <td>12.8</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>283.6</td>\n      <td>42.0</td>\n      <td>66.2</td>\n      <td>25.5</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>232.1</td>\n      <td>8.6</td>\n      <td>8.7</td>\n      <td>13.4</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv('./Advertising.csv')\n",
    "df_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV           0.782224\n",
      "radio        0.576223\n",
      "newspaper    0.228299\n",
      "sales        1.000000\n",
      "Name: sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_data = df_data.corr('pearson')\n",
    "# 说明都有线性关系，或强或弱\n",
    "print(corr_data.loc['sales'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Y = df_data.pop('sales').values\n",
    "df_data.insert(0, 'bias', np.ones(df_data.shape[0]))\n",
    "X = df_data.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  1. , 230.1,  37.8,  69.2],\n       [  1. ,  44.5,  39.3,  45.1],\n       [  1. ,  17.2,  45.9,  69.3],\n       [  1. , 151.5,  41.3,  58.5],\n       [  1. , 180.8,  10.8,  58.4],\n       [  1. ,   8.7,  48.9,  75. ],\n       [  1. ,  57.5,  32.8,  23.5],\n       [  1. , 120.2,  19.6,  11.6],\n       [  1. ,   8.6,   2.1,   1. ],\n       [  1. , 199.8,   2.6,  21.2],\n       [  1. ,  66.1,   5.8,  24.2],\n       [  1. , 214.7,  24. ,   4. ],\n       [  1. ,  23.8,  35.1,  65.9],\n       [  1. ,  97.5,   7.6,   7.2],\n       [  1. , 204.1,  32.9,  46. ],\n       [  1. , 195.4,  47.7,  52.9],\n       [  1. ,  67.8,  36.6, 114. ],\n       [  1. , 281.4,  39.6,  55.8],\n       [  1. ,  69.2,  20.5,  18.3],\n       [  1. , 147.3,  23.9,  19.1],\n       [  1. , 218.4,  27.7,  53.4],\n       [  1. , 237.4,   5.1,  23.5],\n       [  1. ,  13.2,  15.9,  49.6],\n       [  1. , 228.3,  16.9,  26.2],\n       [  1. ,  62.3,  12.6,  18.3],\n       [  1. , 262.9,   3.5,  19.5],\n       [  1. , 142.9,  29.3,  12.6],\n       [  1. , 240.1,  16.7,  22.9],\n       [  1. , 248.8,  27.1,  22.9],\n       [  1. ,  70.6,  16. ,  40.8],\n       [  1. , 292.9,  28.3,  43.2],\n       [  1. , 112.9,  17.4,  38.6],\n       [  1. ,  97.2,   1.5,  30. ],\n       [  1. , 265.6,  20. ,   0.3],\n       [  1. ,  95.7,   1.4,   7.4],\n       [  1. , 290.7,   4.1,   8.5],\n       [  1. , 266.9,  43.8,   5. ],\n       [  1. ,  74.7,  49.4,  45.7],\n       [  1. ,  43.1,  26.7,  35.1],\n       [  1. , 228. ,  37.7,  32. ],\n       [  1. , 202.5,  22.3,  31.6],\n       [  1. , 177. ,  33.4,  38.7],\n       [  1. , 293.6,  27.7,   1.8],\n       [  1. , 206.9,   8.4,  26.4],\n       [  1. ,  25.1,  25.7,  43.3],\n       [  1. , 175.1,  22.5,  31.5],\n       [  1. ,  89.7,   9.9,  35.7],\n       [  1. , 239.9,  41.5,  18.5],\n       [  1. , 227.2,  15.8,  49.9],\n       [  1. ,  66.9,  11.7,  36.8],\n       [  1. , 199.8,   3.1,  34.6],\n       [  1. , 100.4,   9.6,   3.6],\n       [  1. , 216.4,  41.7,  39.6],\n       [  1. , 182.6,  46.2,  58.7],\n       [  1. , 262.7,  28.8,  15.9],\n       [  1. , 198.9,  49.4,  60. ],\n       [  1. ,   7.3,  28.1,  41.4],\n       [  1. , 136.2,  19.2,  16.6],\n       [  1. , 210.8,  49.6,  37.7],\n       [  1. , 210.7,  29.5,   9.3],\n       [  1. ,  53.5,   2. ,  21.4],\n       [  1. , 261.3,  42.7,  54.7],\n       [  1. , 239.3,  15.5,  27.3],\n       [  1. , 102.7,  29.6,   8.4],\n       [  1. , 131.1,  42.8,  28.9],\n       [  1. ,  69. ,   9.3,   0.9],\n       [  1. ,  31.5,  24.6,   2.2],\n       [  1. , 139.3,  14.5,  10.2],\n       [  1. , 237.4,  27.5,  11. ],\n       [  1. , 216.8,  43.9,  27.2],\n       [  1. , 199.1,  30.6,  38.7],\n       [  1. , 109.8,  14.3,  31.7],\n       [  1. ,  26.8,  33. ,  19.3],\n       [  1. , 129.4,   5.7,  31.3],\n       [  1. , 213.4,  24.6,  13.1],\n       [  1. ,  16.9,  43.7,  89.4],\n       [  1. ,  27.5,   1.6,  20.7],\n       [  1. , 120.5,  28.5,  14.2],\n       [  1. ,   5.4,  29.9,   9.4],\n       [  1. , 116. ,   7.7,  23.1],\n       [  1. ,  76.4,  26.7,  22.3],\n       [  1. , 239.8,   4.1,  36.9],\n       [  1. ,  75.3,  20.3,  32.5],\n       [  1. ,  68.4,  44.5,  35.6],\n       [  1. , 213.5,  43. ,  33.8],\n       [  1. , 193.2,  18.4,  65.7],\n       [  1. ,  76.3,  27.5,  16. ],\n       [  1. , 110.7,  40.6,  63.2],\n       [  1. ,  88.3,  25.5,  73.4],\n       [  1. , 109.8,  47.8,  51.4],\n       [  1. , 134.3,   4.9,   9.3],\n       [  1. ,  28.6,   1.5,  33. ],\n       [  1. , 217.7,  33.5,  59. ],\n       [  1. , 250.9,  36.5,  72.3],\n       [  1. , 107.4,  14. ,  10.9],\n       [  1. , 163.3,  31.6,  52.9],\n       [  1. , 197.6,   3.5,   5.9],\n       [  1. , 184.9,  21. ,  22. ],\n       [  1. , 289.7,  42.3,  51.2],\n       [  1. , 135.2,  41.7,  45.9],\n       [  1. , 222.4,   4.3,  49.8],\n       [  1. , 296.4,  36.3, 100.9],\n       [  1. , 280.2,  10.1,  21.4],\n       [  1. , 187.9,  17.2,  17.9],\n       [  1. , 238.2,  34.3,   5.3],\n       [  1. , 137.9,  46.4,  59. ],\n       [  1. ,  25. ,  11. ,  29.7],\n       [  1. ,  90.4,   0.3,  23.2],\n       [  1. ,  13.1,   0.4,  25.6],\n       [  1. , 255.4,  26.9,   5.5],\n       [  1. , 225.8,   8.2,  56.5],\n       [  1. , 241.7,  38. ,  23.2],\n       [  1. , 175.7,  15.4,   2.4],\n       [  1. , 209.6,  20.6,  10.7],\n       [  1. ,  78.2,  46.8,  34.5],\n       [  1. ,  75.1,  35. ,  52.7],\n       [  1. , 139.2,  14.3,  25.6],\n       [  1. ,  76.4,   0.8,  14.8],\n       [  1. , 125.7,  36.9,  79.2],\n       [  1. ,  19.4,  16. ,  22.3],\n       [  1. , 141.3,  26.8,  46.2],\n       [  1. ,  18.8,  21.7,  50.4],\n       [  1. , 224. ,   2.4,  15.6],\n       [  1. , 123.1,  34.6,  12.4],\n       [  1. , 229.5,  32.3,  74.2],\n       [  1. ,  87.2,  11.8,  25.9],\n       [  1. ,   7.8,  38.9,  50.6],\n       [  1. ,  80.2,   0. ,   9.2],\n       [  1. , 220.3,  49. ,   3.2],\n       [  1. ,  59.6,  12. ,  43.1],\n       [  1. ,   0.7,  39.6,   8.7],\n       [  1. , 265.2,   2.9,  43. ],\n       [  1. ,   8.4,  27.2,   2.1],\n       [  1. , 219.8,  33.5,  45.1],\n       [  1. ,  36.9,  38.6,  65.6],\n       [  1. ,  48.3,  47. ,   8.5],\n       [  1. ,  25.6,  39. ,   9.3],\n       [  1. , 273.7,  28.9,  59.7],\n       [  1. ,  43. ,  25.9,  20.5],\n       [  1. , 184.9,  43.9,   1.7],\n       [  1. ,  73.4,  17. ,  12.9],\n       [  1. , 193.7,  35.4,  75.6],\n       [  1. , 220.5,  33.2,  37.9],\n       [  1. , 104.6,   5.7,  34.4],\n       [  1. ,  96.2,  14.8,  38.9],\n       [  1. , 140.3,   1.9,   9. ],\n       [  1. , 240.1,   7.3,   8.7],\n       [  1. , 243.2,  49. ,  44.3],\n       [  1. ,  38. ,  40.3,  11.9],\n       [  1. ,  44.7,  25.8,  20.6],\n       [  1. , 280.7,  13.9,  37. ],\n       [  1. , 121. ,   8.4,  48.7],\n       [  1. , 197.6,  23.3,  14.2],\n       [  1. , 171.3,  39.7,  37.7],\n       [  1. , 187.8,  21.1,   9.5],\n       [  1. ,   4.1,  11.6,   5.7],\n       [  1. ,  93.9,  43.5,  50.5],\n       [  1. , 149.8,   1.3,  24.3],\n       [  1. ,  11.7,  36.9,  45.2],\n       [  1. , 131.7,  18.4,  34.6],\n       [  1. , 172.5,  18.1,  30.7],\n       [  1. ,  85.7,  35.8,  49.3],\n       [  1. , 188.4,  18.1,  25.6],\n       [  1. , 163.5,  36.8,   7.4],\n       [  1. , 117.2,  14.7,   5.4],\n       [  1. , 234.5,   3.4,  84.8],\n       [  1. ,  17.9,  37.6,  21.6],\n       [  1. , 206.8,   5.2,  19.4],\n       [  1. , 215.4,  23.6,  57.6],\n       [  1. , 284.3,  10.6,   6.4],\n       [  1. ,  50. ,  11.6,  18.4],\n       [  1. , 164.5,  20.9,  47.4],\n       [  1. ,  19.6,  20.1,  17. ],\n       [  1. , 168.4,   7.1,  12.8],\n       [  1. , 222.4,   3.4,  13.1],\n       [  1. , 276.9,  48.9,  41.8],\n       [  1. , 248.4,  30.2,  20.3],\n       [  1. , 170.2,   7.8,  35.2],\n       [  1. , 276.7,   2.3,  23.7],\n       [  1. , 165.6,  10. ,  17.6],\n       [  1. , 156.6,   2.6,   8.3],\n       [  1. , 218.5,   5.4,  27.4],\n       [  1. ,  56.2,   5.7,  29.7],\n       [  1. , 287.6,  43. ,  71.8],\n       [  1. , 253.8,  21.3,  30. ],\n       [  1. , 205. ,  45.1,  19.6],\n       [  1. , 139.5,   2.1,  26.6],\n       [  1. , 191.1,  28.7,  18.2],\n       [  1. , 286. ,  13.9,   3.7],\n       [  1. ,  18.7,  12.1,  23.4],\n       [  1. ,  39.5,  41.1,   5.8],\n       [  1. ,  75.5,  10.8,   6. ],\n       [  1. ,  17.2,   4.1,  31.6],\n       [  1. , 166.8,  42. ,   3.6],\n       [  1. , 149.7,  35.6,   6. ],\n       [  1. ,  38.2,   3.7,  13.8],\n       [  1. ,  94.2,   4.9,   8.1],\n       [  1. , 177. ,   9.3,   6.4],\n       [  1. , 283.6,  42. ,  66.2],\n       [  1. , 232.1,   8.6,   8.7]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加截距项\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "\n",
    "# 参数估计\n",
    "def cal_beta_hat(x, y):\n",
    "    return np.dot(np.dot(inv(np.dot(x.T, x)), x.T), y)\n",
    "\n",
    "\n",
    "def cal_q(x, y):\n",
    "    beta = cal_beta_hat(x, y)\n",
    "    temp = y - np.dot(x, beta)\n",
    "    return np.dot(temp.T, temp)\n",
    "\n",
    "\n",
    "def cal_sigma_hat_2(x, y):\n",
    "    q = cal_q(x, y)\n",
    "    return q / (x.shape[0] - x.shape[1] - 1)\n",
    "\n",
    "\n",
    "def cal_u(x, y):\n",
    "    # 因为Lyy = U + Q\n",
    "    return y.var() * y.shape[0] - cal_q(x, y)\n",
    "\n",
    "\n",
    "# 偏回归平方和:\n",
    "def cal_F(indices: set, y, mode=0, additional_index=None):\n",
    "    \"\"\"\n",
    "    获取自变量的F，用于判断是否引入/删除此自变量\n",
    "\n",
    "    其中mode=0时代表计算当前集合的线性回归；mode=1代表逐步回归中的引入；mode=2代表逐步回归中的排除\n",
    "    \"\"\"\n",
    "    if mode == 0:\n",
    "        indices = list(indices)\n",
    "        x = X[:, indices]\n",
    "        return (x.shape[0] - 2) * cal_u(x, y) / cal_q(x, y)\n",
    "    else:\n",
    "        if mode == 1:\n",
    "            new_indices = indices.copy()\n",
    "            new_indices.add(additional_index)\n",
    "            x = X[:, list(indices)]\n",
    "            new_x = X[:, list(new_indices)]\n",
    "            old_u = cal_u(x, y)\n",
    "            new_u = cal_u(new_x, y)\n",
    "            return (new_u - old_u) / cal_sigma_hat_2(new_x, y)\n",
    "        else:\n",
    "            new_indices = indices.copy()\n",
    "            new_indices.remove(additional_index)\n",
    "            x = X[:, list(indices)]\n",
    "            new_x = X[:, list(new_indices)]\n",
    "            old_u = cal_u(x, y)\n",
    "            new_u = cal_u(new_x, y)\n",
    "            return (old_u - new_u) / cal_sigma_hat_2(x, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一元：引入变量TV\n",
      "多元：引入变量radio，现在显著因素有['bias' 'TV' 'radio']\n",
      "多元：对变量radio的后退判断已经结束，现在显著因素有['bias' 'TV' 'radio']\n",
      "最大的偏F为0.031068718342499267，而显著性水平0.05下的F_alpha(1, 195)为3.8895888198396573，没有其他显著因素，回归结束\n",
      "多元回归结束，显著因素有['bias' 'TV' 'radio' 'newspaper']\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "ADDITION = 1\n",
    "DELETION = 2\n",
    "\n",
    "\n",
    "def stepwise_regression():\n",
    "    # 逐步回归选择最佳模型\n",
    "    in_alpha = 0.05\n",
    "    # 引入的显著性水平应小于排除的显著性水平，否则将会死循环\n",
    "    out_alpha = 0.1\n",
    "    p = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    max_F = -1\n",
    "    max_ind = -1\n",
    "    # 找到最大一元回归\n",
    "    for i in range(1, p):\n",
    "        if (new_F := cal_F({0, i}, Y)) > max_F:\n",
    "            max_F = new_F\n",
    "            max_ind = i\n",
    "\n",
    "    # 先判断这个一元是否满足显著性假设，不满足则直接失败。\n",
    "    F_alpha = f.isf(in_alpha, 1, n - 2)\n",
    "    assert max_F >= F_alpha, f\"最大的偏F为{max_F}，而显著性水平{in_alpha}下的F_alpha(1, {n - 2})为{F_alpha}，\" \\\n",
    "                             f\"一元回归没有显著因素，回归结束\"\n",
    "    print(f\"一元：引入变量{df_data.columns[max_ind]}\")\n",
    "    selected_indices = set()\n",
    "    # 截距项一定要考虑\n",
    "    selected_indices.add(0)\n",
    "    selected_indices.add(max_ind)\n",
    "\n",
    "    while True:\n",
    "        max_F = -1\n",
    "        max_ind = -1\n",
    "        if len(selected_indices) == p:\n",
    "            break\n",
    "        # 开始前进\n",
    "        for i in range(p):\n",
    "            if i not in selected_indices:\n",
    "                if (new_F := cal_F(selected_indices, Y, ADDITION, i)) > max_F:\n",
    "                    max_F = new_F\n",
    "                    max_ind = i\n",
    "        selected_indices.add(max_ind)\n",
    "        F_alpha = f.isf(in_alpha, 1, n - len(selected_indices) - 1)\n",
    "        if max_F < F_alpha:\n",
    "            print(f\"最大的偏F为{max_F}，而显著性水平{in_alpha}下的F_alpha(1, {n - len(selected_indices) - 1})\"\n",
    "                  f\"为{F_alpha}，没有其他显著因素，回归结束\")\n",
    "            break\n",
    "        print(f\"多元：引入变量{df_data.columns[max_ind]}，现在显著因素有{df_data.columns[list(selected_indices)].values}\")\n",
    "        # 开始后退\n",
    "        out_flag = True\n",
    "        while out_flag:\n",
    "            out_flag = False\n",
    "            F_alpha = f.isf(out_alpha, 1, n - len(selected_indices) - 1)\n",
    "            for i in selected_indices:\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                tmp = cal_F(selected_indices, Y, DELETION, i)\n",
    "                if tmp < F_alpha:\n",
    "                    selected_indices.remove(i)\n",
    "                    print(f\"多元：引入变量{df_data.columns[max_ind]}后，判断偏回归平方和变化，\"\n",
    "                          f\"删除变量{df_data.columns[i]}，现在显著因素有{df_data.columns[selected_indices].values}\")\n",
    "                    out_flag = True\n",
    "                    break\n",
    "        print(f\"多元：对变量{df_data.columns[max_ind]}的后退判断已经结束，\"\n",
    "              f\"现在显著因素有{df_data.columns[list(selected_indices)].values}\")\n",
    "\n",
    "    print(f\"多元回归结束，显著因素有{df_data.columns[list(selected_indices)].values}\")\n",
    "    return selected_indices\n",
    "\n",
    "efficient_attribute_indices = stepwise_regression()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多元回归的显著性检验F值 = 425.5208694395026，而在显著性水平0.05的情况下F(4, 195)为2.4179625418439827，所以该多元回归有显著性\n",
      "此时的多元回归方程为：sales = 2.938889 + 0.045765 * TV + 0.188530 * radio + -0.001037 * newspaper \n"
     ]
    }
   ],
   "source": [
    "# 回归效果显著性检验\n",
    "n = Y.shape[0]\n",
    "p = len(efficient_attribute_indices)\n",
    "eff_test_f = (n - p - 1) * cal_u(X[:,list(efficient_attribute_indices)], Y) / p / cal_q(X[:,list(efficient_attribute_indices)], Y)\n",
    "\n",
    "alpha = 0.05\n",
    "F_alpha = f.isf(alpha, p, n - p - 1)\n",
    "print(f\"多元回归的显著性检验F值 = {eff_test_f}，而在显著性水平{alpha}的情况下F({p}, {n - p - 1})为{F_alpha}，\"\n",
    "      f\"所以该多元回归{'没' if eff_test_f < F_alpha else ''}有显著性\")\n",
    "\n",
    "if eff_test_f >= F_alpha:\n",
    "    beta = cal_beta_hat(X[:,list(efficient_attribute_indices)], Y)\n",
    "    print_str = f\"此时的多元回归方程为：sales = {beta[0]:.6f} \"\n",
    "    for i in range(1, len(efficient_attribute_indices)):\n",
    "        print_str += f'+ {beta[i]:.6f} * {df_data.columns[i]} '\n",
    "    print(print_str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8972106381789522"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试sklearn包中的线性回归\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression(fit_intercept=False).fit(X,Y)\n",
    "reg.score(X, Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 2.93888937e+00,  4.57646455e-02,  1.88530017e-01, -1.03749304e-03])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_\n",
    "# 可以观察到，和手动算的结果一致。"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
